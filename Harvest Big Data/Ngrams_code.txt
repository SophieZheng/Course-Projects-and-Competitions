N-grams

from pyspark.ml.feature import NGram
ngram = NGram(inputCol="filtered", outputCol="ngrams")
jsqngramDF = ngram.transform(c)


Finding the frequency of N-grams 
jsqngramRDD=jsqngramDF.select("ngrams").rdd
jsqRDD1=jsqngramRDD.flatMap(lambda row: [str(c).split(",") for c in row[0]])
jsqRDD2=jsqRDD1.map(lambda word: (word[0].lower(),1)).
jsqRDD3=jsqRDD2.reduceByKey(lambda v1,v2: v1+v2)
jsqRDD4=jsqRDD3.map(lambda line: (line[1],line[0]))
jsqRDD5=jsqRDD4.sortByKey(ascending=False).map(lambda line: (line[0],line[1]))


Writing the top ngrams to a csv file for wordcloud visualization in R


def toCSVLine(data):
  return ','.join(str(d) for d in data)


lines = jsngramRDD.map(toCSVLine)
lines.saveAsTextFile('file:/home/cloudera/project/topngrams.csv')


R Code for generating wordcloud


require(wordcloud)
js.d <- read.csv('topngrams.csv',header=False, col.names=c('word','freq'))
pal <- brewer.pal(9,"PuRd")
pal <- pal[-(1:4)]
set.seed(123)
wordcloud(words = js.d$word, freq = js.d$freq , scale=c(2,0.1), max.words=100, random.order=FALSE, 
          rot.per=0.3,colors = pal)
